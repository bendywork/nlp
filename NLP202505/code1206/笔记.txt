多项式扩展 + LR
    原始
        特征属性: x1、x2、x3
        目标属性: y
        LR预测函数: p = sigmoid(w1*x1+w2*x2+w3*x3)
    二阶的多项式扩展:
        特征属性:
            x1、x2、x3、x1*x2、x1*x3、x2*x3、x1^2、x2^2、x3^2
        目标属性: y
        LR预测函数: p = sigmoid(
                w1*x1 + w2*x2 + w3*x3 +
                w4*x1*x2 + w5*x1*x3 + w6*x2*x3 +
                w7*x1^2 + w8*x2^2 + w9*x3^2
            )
        多项式扩展相当于将坐标系做了一个转换，是从低维到高维的一个映射
        多项式扩展就相当于是一种映射函数(理解成神经元的功能)
            z1=f1(x1,x2,x3)=x1
            z2=f2(x1,x2,x3)=x2
            z3=f3(x1,x2,x3)=x3
            z4=f4(x1,x2,x3)=x1*x2
            z5=f5(x1,x2,x3)=x1*x3
            z6=f6(x1,x2,x3)=x2*x3
            z7=f7(x1,x2,x3)=x1^2
            z8=f8(x1,x2,x3)=x2^2
            z9=f9(x1,x2,x3)=x3^2
    NOTE: 多项式扩展是不是就是将原始的特征属性(x1,x2,x3); 通过映射函数(神经元)映射到(z1,z2,z3,z4,z5,z6,z7,z8,z9)后，就会发现原来线性不可分的数据变成了线性可分。
        eg:
            (1,5,3) -> (1,5,3,5,3,15,1,25,9)
    深度学习：
        个人认为深度学习/神经网络是LR(线性转换+激活函数)的堆叠
        原始数据:
            x1,x2
            p=sigmoid(w1*x1+w2*x2+b)
        二阶多项式扩展数据:
            x1,x2,x1^2、x2^2
            p=sigmoid(w1*x1 + w2*x2 + w3*x1^2 + w4*x2^2 + b)
                z1=f1(x1,x2)=x1
                z2=f2(x1,x2)=x2
                z3=f3(x1,x2)=x1^2
                z4=f4(x1,x2)=x2^2
                p = sigmoid(w1*z1 + w2*z2 + w3*z3 + w4*z4 + b)
        深度学习数据:
            x1,x2 --> z1,z2,z3 --> p
                z1=f1(x1,x2)=tanh(-1.2*x1-0.13*x2-2.0)
                z2=f2(x1,x2)=tanh(-0.58*x1-1.3*x2+3.0)
                z3=f3(x1,x2)=tanh(0.82*x1-1.1*x2-3.0)
                p = sigmoid(-1.7*z1 + 1.8*z2 + -1.8*z3 + 0.0)
            每个神经元的功能就是提取特征信息，对每个样本而言每个神经元(每组参数)相当于从某个方面进行特征的描述/特征的提取；至于每个神经元具体提取什么特征由参数决定，参数又由当前模型的训练数据决定(损失最小化)
        NOTE:
            如果没有激活函数的时候，不管深度学习的网络有多少层，都相当于单层的线性模型
                p = sigmoid(-1.7*z1 + 1.8*z2 + -1.8*z3 + 0.0)
                    = sigmoid(
                            -1.7*(-1.2*x1-0.13*x2-2.0) +
                            1.8*(-0.58*x1-1.3*x2+3.0) +
                            -1.8*(0.82*x1-1.1*x2-3.0) +
                            0.0
                        )
                    = sigmoid(-0.48 * x1 + -0.139 * x2 + 14.2)
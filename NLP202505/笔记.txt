一、作业
    作业代码(所有) + 运行截图 + 必要的文字&文档说明邮件发压缩包发1941046624@qq.com并抄送834822435@qq.com
    20251207:
        一、基于python原生代码(不依赖任何第三方库的情况)实现一下序号化转换、文本/Token哑编码转换、文本词袋法转换、文本TF-IDF转换的实现
        二、结合分词、token向量化转换 + 机器学习(LR)/深度学习，完成datas/text_classify文件夹中的文本分类模型的训练
            完成：
                训练: 如果替换一个数据集，如何在最小改动的情况下，完成新数据集的模型训练
                推理：在训练完成的基础上，最终支持给定任何一个文本，返回该文本对应的类别id、类别名称以及预测所属概率，支持返回TopK的结果；


================================================================
简单总结：
    1. NLP相关知识点脉络
        分词 -> Word2Vec -> RNN/LSTM/GRU -> Seq2Seq -> Attention -> Transformer -> Bert/T5/GPT -> LLM
        NOTE:
            NLP内部神经网络本质上都是在做特征向量提取，在获取token向量以及文本向量；
            静态词向量: token对应的向量是固定，不受上下文其它token的影响 --> 一般就是一个固定的embedding table映射表
                代表算法：Word2Vec
            动态词向量：token对应的向量是非固定的，受上下文其它token的影响，也就是上下文不同的时候，当前token对应的最终词也不一样呀 --> 一般是一个网络结构，需要执行获取token向量
                代表算法：以Bert为首的一些算法、ELMo(Bi-LSTM)
    2. 神经网络中的神经元(线性转换 + 激活函数)的作用？
    3. BP过程？
    4. Token处理方式的介绍：词、字、笔画、偏旁、Byte
    5. 序号化处理
    6. One-Hot哑编码是什么？以及和Word2Vec的区别?
    7. 词袋法、TF-IDF的执行过程、特点以及和Word2Vec的区别?